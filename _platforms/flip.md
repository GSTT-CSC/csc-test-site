---
layout: platform_page
platform-name: FLIP
platform-image: /assets/img/platforms/flip_logo.png
---

FLIP, the Federated Learning Interoperability Platform, links data from multiple Trusts to enable AI at scale. This approach empowers individual Trusts to train their models on, and reap the resulting benefits, of both higher-quality (via its standardisation and enrichment) and larger sets of data, all whilst adhering to national, local and international governance and data privacy regulations.

It is composed of three core components:

- **Secure Enclave**
  > Data from participating Trusts will be transferred into their respective local secure enclaves for curation and aggregation, including both imaging and non-imaging electronic healthcare data. 
- **Federated learning (FL)**
  >  Algorithmic models will be sent to multiple Trusts and iteratively trained on their local data before being securely combined to achieve an optimised consensus model. Due to the FL approach of distributed training of machine learning (ML) models with remotely hosted datasets without the need to share the data beyond each Trust's firewalls, data protection and compliance with local governance practices is ensured. 
- **Interoperability and data harmonisation**
  > Unifying imaging and non-imaging electronic healthcare data is a complex and difficult process, which can raise the barriers to individual Trusts developing and deploying AI models, let alone at scale. By using ontological and data interoperability standards to structure and harmonise the data, FLIP enables participating Trusts to fast-forward their development of interoperable algorithms and derive meaningful data insights.